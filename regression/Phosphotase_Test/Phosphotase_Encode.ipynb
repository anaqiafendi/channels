{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python361064bitgpmodelcondadf662a052f7548da8f1cfb5439246441",
   "display_name": "Python 3.6.10 64-bit ('GP_Model': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import encoding_tools\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# ML imports\n",
    "from sklearn import linear_model\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from scipy.spatial import distance\n",
    "from scipy import optimize, linalg\n",
    "import scipy\n",
    "from sklearn.model_selection import KFold # import KFold\n",
    "\n",
    "# custom imports\n",
    "import encoding_tools as encoding\n",
    "import chimera_tools as chimera\n",
    "import GP_tools as GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "Processed_Folder = Path(r\"Phosphotase_Encode.ipynb\").parent.absolute() / Path(\"Processed Data\")\n",
    "\n",
    "dicts = ['EFI_ID_List', 'metabolite_dict', 'Protein_seq_dict']\n",
    "\n",
    "with open(Processed_Folder / Path('EFI_ID_List.p'), 'rb') as EFI_ID:\n",
    "    EFI_ID_List = pickle.load(EFI_ID)\n",
    "\n",
    "with open(Processed_Folder / Path('metabolite_dict.p'), 'rb') as metabolite:\n",
    "    metabolite_dict = pickle.load(metabolite)\n",
    "\n",
    "with open(Processed_Folder / Path('Protein_seq_dict.p'), 'rb') as Protein_seq:\n",
    "    Protein_seq_dict = pickle.load(Protein_seq)\n",
    "\n",
    "activations = pd.read_csv(Processed_Folder / Path('activations.csv'), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to pad protein sequences to the max length of the longest one\n",
    "max_len = len(max(Protein_seq_dict.values(), key=len))\n",
    "fillchar = '-' # This is whats used in the GP-UCB paper\n",
    "Padded_dict = {}\n",
    "OH_dict = {}\n",
    "for ID in EFI_ID_List:\n",
    "    Padded_dict[ID] = Protein_seq_dict[ID].upper().ljust(max_len, fillchar)\n",
    "    OH_dict[ID] = encoding_tools.one_hot_seq(seq_input=Padded_dict[ID])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing input training data X to feed into ML Model\n",
    "input_len = len(OH_dict[EFI_ID_List[0]])*21\n",
    "num_inputs = len(OH_dict.keys())\n",
    "\n",
    "X = np.zeros((num_inputs,input_len))\n",
    "for i in range(0,len(EFI_ID_List)):\n",
    "    ID = EFI_ID_List[i]\n",
    "    X_seq = OH_dict[ID]\n",
    "    X_seq = np.reshape(X_seq,(1,X_seq.shape[0]*21))\n",
    "    X[i,:] = X_seq\n",
    "\n",
    "# Preapre output training data y to feed into ML Model\n",
    "y = activations.values[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "604\n114\n"
    }
   ],
   "source": [
    "ID = np.random.randint(low=0,high=218)\n",
    "len_comp = len(Padded_dict[EFI_ID_List[ID]])\n",
    "len(Padded_dict[EFI_ID_List[0]]) == len(Padded_dict[EFI_ID_List[ID]])\n",
    "print(len_comp)\n",
    "print(ID) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ML_train(X, y):\n",
    "    # test the optimization of the hyp-prams\n",
    "    initial_guess = [0.9,0.9]\n",
    "\n",
    "    # take the log of the initial guess for optimiziation \n",
    "    initial_guess_log = np.log(initial_guess)\n",
    "\n",
    "    # optimize to fit model\n",
    "    result = scipy.optimize.minimize(GP.neg_log_marg_likelihood, initial_guess_log, args=(X,y), method='L-BFGS-B')\n",
    "    \n",
    "    print('Full GP regression model')\n",
    "    print('Hyperparameters: ' + str(np.exp(result.x[0])) + ' ' + str(np.exp(result.x[1])))\n",
    "\n",
    "    # next set of hyper prams \n",
    "    final_prams = [np.exp(result.x[0]), np.exp(result.x[1])]\n",
    "    \n",
    "    return final_prams\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Full GP regression model\nHyperparameters: 2.24125819484e-11 203.879134241\n"
    }
   ],
   "source": [
    "final_prams = ML_train(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}